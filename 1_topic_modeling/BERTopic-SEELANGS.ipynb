{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXHLDxJdRzBi"
   },
   "source": [
    "# BERTopic - Tutorial\n",
    "We start with installing bertopic from pypi before preparing the data. \n",
    "\n",
    "**NOTE**: Make sure to select a GPU runtime. Otherwise, the model can take quite some time to create the document embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "SNa-KtKDRnus",
    "outputId": "f7ed585b-858d-4a70-dedf-31aa9748fac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (0.23.2)\n",
      "Requirement already satisfied: hdbscan in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (0.8.26)\n",
      "Requirement already satisfied: torch in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (1.6.0)\n",
      "Requirement already satisfied: numpy in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (1.19.1)\n",
      "Requirement already satisfied: sentence-transformers in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (0.3.7.2)\n",
      "Requirement already satisfied: joblib in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (0.17.0)\n",
      "Requirement already satisfied: pandas in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (1.1.3)\n",
      "Requirement already satisfied: tqdm in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (4.50.0)\n",
      "Requirement already satisfied: umap-learn in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from bertopic) (0.4.6)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from scikit-learn->bertopic) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from scikit-learn->bertopic) (2.1.0)\n",
      "Requirement already satisfied: six in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from hdbscan->bertopic) (1.15.0)\n",
      "Requirement already satisfied: cython>=0.27 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from hdbscan->bertopic) (0.29.21)\n",
      "Requirement already satisfied: future in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from torch->bertopic) (0.18.2)\n",
      "Requirement already satisfied: transformers<3.4.0,>=3.1.0 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from sentence-transformers->bertopic) (3.3.1)\n",
      "Requirement already satisfied: nltk in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from sentence-transformers->bertopic) (3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from pandas->bertopic) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from pandas->bertopic) (2020.1)\n",
      "Requirement already satisfied: numba!=0.47,>=0.46 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from umap-learn->bertopic) (0.51.2)\n",
      "Requirement already satisfied: filelock in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (0.8.1rc2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (0.1.91)\n",
      "Requirement already satisfied: packaging in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (2020.9.27)\n",
      "Requirement already satisfied: requests in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (2.24.0)\n",
      "Requirement already satisfied: sacremoses in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (0.0.43)\n",
      "Requirement already satisfied: click in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from nltk->sentence-transformers->bertopic) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from numba!=0.47,>=0.46->umap-learn->bertopic) (50.3.0.post20201005)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from numba!=0.47,>=0.46->umap-learn->bertopic) (0.34.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from packaging->transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers->bertopic) (1.25.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3VGFZ1USMTu"
   },
   "source": [
    "# Prepare data\n",
    "For this example, we use the famous 20 Newsgroups dataset which contains roughly 18000 newsgroups posts on 20 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JJij3WP6SEQD"
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    " \n",
    "docs = fetch_20newsgroups(subset='train')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#docs is a list of strings\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<div align=\"left\">\\n<table cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\\n<tbody><tr>\\n<td><a href=\"javascript:print()\"><img src=\"/archives/images/b-print.png\" alt=\"Print\" title=\"Print\" border=\"0\"></a></td>\\n<td><img src=\"/archives/images/b-blank.gif\" alt=\"\" width=\"5\" height=\"1\"></td>\\n<td nowrap=\"\"><p><a href=\"javascript:print()\" style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; font-weight: bold; color: #3366CC; text-decoration: none\">Print</a></p></td>\\n</tr>\\n</tbody></table>\\n<hr>\\n</div>\\n<pre> \\n\\nDear SEELANGERS!\\n\\n \\n\\nI am excited to present to you the latest addition to the SRAS Online lineup. Please share with students, friends, colleagues, other departments, even family members who enjoy learning!\\n\\n \\n\\nНачинаем! Getting Started with Russian\\n\\nWhen: 4 meetings + asynchronous work\\n\\nCost: $99\\n\\nWhat: Looking to “sample” Russian and determine whether it is the language for you? This is a no stress, no test way for you to familiarize yourself with a language that may look intimidating on the surface, but is so rewarding to learn. Our colleagues in Kyiv (morning/early afternoon/Saturday) and Irkutsk (evenings) are ready to introduce the Russian language and convince you that you can and should do it - whether taking a course at your home institution, online, or abroad!\\n\\n \\n\\n***Reminder***\\n\\n \\n\\nWe have a few spots still available in these two upcoming courses:\\n\\n \\n\\nPerspectives on US-Russia Relations\\nWhen: 4 Saturdays, starting Oct 10 (Sessions 1 and 2: 10-12:30 EST, Sessions 3 and 4: 14:00-16:15 EST)\\nCost: $250 (SRAS alumni and groups contact us for special rates)\\nWhat: 2020 has provided us with many opportunities to look at the world from varying perspectives, to consider the rise of globalism and its effects, and to evaluate the relationships between countries. Join us as we examine the US-Russia relationship in depth from the perspectives of history, behavior, foreign policy, and media. This is an invaluable course for students of Russian Studies, International Relations, Journalism, and more. Contact us for more information about the experts in Russia who will present this course.\\n\\n \\n\\nEurasian Foodways: Cooking Vegetarian Georgian\\nWhen: Oct 23, 24, 25 (3 afternoon sessions)\\nCost: $95 (includes copy of Lobio: The Vegetarian Cuisine of Georgia \\nWhat: Whether you are already a fan of Georgian food or you are not even sure what it is, this is a great opportunity to familiarize yourself with some of the fundamental ingredients and their uses in many popular Georgian dishes. We will discuss the history and variety of Georgian cuisine and during each session prepare one dish for you to add to your dinner table that evening.\\n\\n \\n\\n**In other news!**\\n\\n \\n\\nInfo Sessions for IR/Global Studies\\nJoin us for a series of information sessions aimed at students in IR/Global Studies and a range of related fields - security, terrorism, diplomacy, peace, business, and more. In the general sessions we discuss “Building the International Resume” and look at the non-traditional locations offered by SRAS. In our Special Topic Info Session series, the hosts of our programs abroad will do a short talk on a relevant topic, followed by an opportunity for Q&amp;A and discussion with SRAS alumni. Check it out!\\n\\n \\n\\nArchive Support\\n\\nOur archive support services are growing. The current conditions for working with archives are such that even if you could jump on a plane tomorrow, it is not efficient. Limits on working hours and maximum number of delo that can be ordered and the need to reserve limited time slots mean you really need to just find somebody local. If you have friends/colleagues that can do this for you, great. If not, SRAS can help. \\n\\n \\n\\nClassroom Support\\n\\nWe are getting rave reviews on this! If you’d like to learn more about how you might work this into your spring 2021 courses, let us know. Aside from providing a platform for enhancing language learning, our objective is to engage your students so much with the people, language, and countries, so much that they start thinking about study abroad.\\n\\n \\n\\nThese are both challenging and exciting times. I personally am enjoying the ability to attend many of our courses and seeing how it is possible to grow an online community of learners and over time bring more students and others into the Slavic world.\\n\\n \\n\\nBest,\\n\\n \\n\\nRenee Stillings\\nDirector, SRAS\\n\\nwww.SRAS.org\\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n-- Use your web browser to search the archives, control your subscription options, and more. Visit and bookmark the SEELANGS Web Interface at: http://seelangs(dot)wixsite(dot)com/seelangs \\n\\n\\n--\\nUse your web browser to search the archives, control your\\nsubscription options, and more.  Visit and bookmark the\\nSEELANGS Web Interface at:\\nhttp://seelangs(dot)wixsite(dot)com/seelangs\\n\\n</pre>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/ajanco/projects/slavic_review/SEELANGS/SEELANGS.csv')\n",
    "docs = list(df.text)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBcNmZJzSTY8"
   },
   "source": [
    "# Create Topics\n",
    "We use the **distilbert-base-nli-mean-tokens** model as it is the recommended model for creating sentence embeddings according to the authors of the [sentence-embeddings](https://www.sbert.net/docs/pretrained_models.html) package. However, you can use whatever embeddings is currently pre-trained in the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "TfhfzqkoSJ1I",
    "outputId": "ac0e85e6-bd2b-4707-9e15-dc07641f5d3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-15 19:47:56,987 - BERTopic - Loaded BERT model\n",
      "INFO:BERTopic:Loaded BERT model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-06f2c8624cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distilbert-base-nli-mean-tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/bertopic/model.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, documents, debug)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Extract BERT sentence embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Reduce dimensionality with UMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/bertopic/model.py\u001b[0m in \u001b[0;36m_extract_embeddings\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded BERT model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transformed documents to Embeddings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, is_pretokenized, device, num_workers)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Batches\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/sentence_transformers/datasets/EncodeDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tokenized\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mTokenizes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\"\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mescaped_special_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_tok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms_tok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescaped_special_toks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\")|\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"(.+?)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msplit_on_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertopic/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mescaped_special_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_tok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms_tok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescaped_special_toks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\")|\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"(.+?)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msplit_on_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BERTopic(\"distilbert-base-nli-mean-tokens\", verbose=True)\n",
    "topics = model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "nNptKBzHSbyS",
    "outputId": "63e40121-3456-4cff-85b4-499a7a0ae179"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>59051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count\n",
       "0      1  59051\n",
       "1     -1    878\n",
       "2      0     48"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get most frequent topics\n",
    "model.get_topics_freq()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "UCw_q8I7Sb03",
    "outputId": "9634794c-ab79-47f4-ba63-6d4d3ff5f87c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2020', 0.014756688930008855),\n",
       " ('hanna', 0.01176757780860469),\n",
       " ('chuchvaha', 0.009217095125575654),\n",
       " ('https', 0.009173698782757837),\n",
       " ('volha', 0.009114942784486036),\n",
       " ('heidelberg', 0.008340001453894068),\n",
       " ('virtual', 0.008017114644771093),\n",
       " ('wixsite', 0.0070440696481119365),\n",
       " ('lesbian', 0.006728334244283046),\n",
       " ('aug', 0.006030023108767534),\n",
       " ('sras', 0.00542157678931076),\n",
       " ('aksyonov', 0.005351767001042392),\n",
       " ('zoom', 0.0053329133874397685),\n",
       " ('nafta', 0.004989702176733887),\n",
       " ('poetry', 0.004885032950130228),\n",
       " ('adjunct', 0.004722709715659518),\n",
       " ('phd', 0.0047159575324253146),\n",
       " ('online', 0.004713860817263869),\n",
       " ('august', 0.0045312911068235194),\n",
       " ('ires', 0.004507260852800454)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a topic \n",
    "model.get_topic(0)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    \"\"\" Calculate a class-based TF-IDF where m is the number of total documents. \"\"\"\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "\n",
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (3.3.2)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from matplotlib) (1.19.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from matplotlib) (1.2.0)\r\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from matplotlib) (2020.6.20)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from matplotlib) (2.4.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from matplotlib) (7.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from matplotlib) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from matplotlib) (2.8.1)\r\n",
      "Requirement already satisfied: six in /home/ajanco/anaconda3/envs/bertopic/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wekNoQNuUVoU"
   },
   "source": [
    "## Model serialization\n",
    "The model and its internal settings can easily be saved. Note that the documents and embeddings will not be saved. However, UMAP and HDBSCAN will be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWUF1uxiSb_a"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"my_model\")\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_eHBI1jSb6i"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "my_model = BERTopic.load(\"my_model\")\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "c9p-bE-MW_Bp",
    "outputId": "d03141a3-e285-4c99-85c9-ad4c8d0fbe1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('baseball', 0.01534818753609341),\n",
       " ('players', 0.01113384693242755),\n",
       " ('cubs', 0.010651317673247482),\n",
       " ('game', 0.01064425481072388),\n",
       " ('braves', 0.010439585241772109),\n",
       " ('pitching', 0.009477156669897367),\n",
       " ('games', 0.009166144809830891),\n",
       " ('runs', 0.009154570979537589),\n",
       " ('year', 0.008982491530594413),\n",
       " ('team', 0.00894693731063402)]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.get_topic(4)[:10]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERTopic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "BERTopic",
   "language": "python",
   "name": "bertopic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
